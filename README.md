# ScorpiusAO

**AI Copilot for French Public Tender Bid Management**

Application IA destinÃ©e aux bid managers pour rÃ©pondre aux appels d'offres publics franÃ§ais, spÃ©cialisÃ©e dans les infrastructures IT, l'hÃ©bergement datacenter et les services de support IT.

## ğŸš€ Quick Start

### AccÃ¨s aux interfaces

- **RabbitMQ Management**: http://localhost:15672 (guest/guest)
- **MinIO Console**: http://localhost:9001 (minioadmin/minioadmin)

## ğŸ“ Structure du projet

```
ScorpiusAO/
â”œâ”€â”€ backend/              # API FastAPI + services Python
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/v1/      # Endpoints REST
â”‚   â”‚   â”œâ”€â”€ services/    # LLM, RAG, Parser
â”‚   â”‚   â”œâ”€â”€ models/      # SQLAlchemy models
â”‚   â”‚   â”œâ”€â”€ schemas/     # Pydantic schemas
â”‚   â”‚   â””â”€â”€ tasks/       # Celery async tasks
â”‚   â”œâ”€â”€ alembic/         # Database migrations
â”‚   â”œâ”€â”€ tests/
â”‚   â””â”€â”€ docker-compose.yml
â”œâ”€â”€ frontend/            # (Ã€ venir) Next.js + TypeScript
â””â”€â”€ CLAUDE.md           # Documentation pour Claude Code

```

## ğŸ› ï¸ Technologies

### Backend
- **API**: FastAPI (Python 3.11+)
- **AI**: Claude Sonnet 4.5, OpenAI Embeddings
- **Database**: PostgreSQL 15 + pgvector
- **Cache**: Redis 7
- **Queue**: RabbitMQ + Celery
- **Storage**: MinIO (S3-compatible)
- **OCR**: Tesseract

### Frontend (Ã€ venir)
- **Framework**: Next.js 14+
- **Language**: TypeScript
- **UI**: React + TailwindCSS

## ğŸ“‹ Prochaines Ã©tapes

### Backend
1. âœ… Structure du projet crÃ©Ã©e
2. âœ… Services d'infrastructure lancÃ©s
3. â³ CrÃ©er les migrations de base de donnÃ©es
4. â³ Tester les endpoints API
5. â³ ImplÃ©menter les services (LLM, RAG, Parser)

### Frontend
1. â³ Initialiser le projet Next.js
2. â³ CrÃ©er les composants UI
3. â³ IntÃ©grer avec l'API backend

## ğŸ”§ Commandes utiles

### Backend

```bash
cd backend

# CrÃ©er et appliquer une migration
alembic revision --autogenerate -m "description"
alembic upgrade head

# DÃ©marrer l'API (dÃ©veloppement local)
uvicorn app.main:app --reload --port 8000

# DÃ©marrer Celery worker (DÃ‰VELOPPEMENT - mode solo pour compatibilitÃ© asyncio)
celery -A app.core.celery_app worker --pool=solo --loglevel=info

# DÃ©marrer Celery worker (PRODUCTION - voir note ci-dessous)
# celery -A app.core.celery_app worker --loglevel=info

# Tests
pytest
pytest --cov=app
```

### Docker

```bash
cd backend

# DÃ©marrer tous les services
docker-compose up -d

# Voir les logs
docker-compose logs -f

# ArrÃªter les services
docker-compose down

# RÃ©initialiser (supprime les donnÃ©es)
docker-compose down -v
```

## ğŸ“š Documentation

- [CLAUDE.md](CLAUDE.md) - Guide complet pour Claude Code
- [Backend README](backend/README.md) - Documentation backend dÃ©taillÃ©e
- API Docs: http://localhost:8000/docs (une fois l'API lancÃ©e)

## ğŸ¯ FonctionnalitÃ©s principales

1. **Analyse d'appels d'offres**
   - Extraction automatique des critÃ¨res
   - Identification des documents obligatoires
   - Analyse des risques et dates limites

2. **GÃ©nÃ©ration de rÃ©ponses**
   - Sections gÃ©nÃ©rÃ©es par IA adaptÃ©es au contexte
   - BibliothÃ¨que de rÃ©ponses rÃ©utilisables
   - VÃ©rification de conformitÃ© en temps rÃ©el

3. **Base de connaissances (RAG)**
   - Recherche sÃ©mantique dans les documents
   - Projets antÃ©rieurs et certifications
   - RÃ©fÃ©rences clients et Ã©tudes de cas

4. **Export de documents**
   - GÃ©nÃ©ration DUME, DC4
   - Formats spÃ©cifiques aux plateformes
   - MÃ©moire technique complet

## ğŸ” Configuration

Copiez `.env.example` vers `.env` et configurez vos clÃ©s API :

```bash
cd backend
cp .env.example .env
# Ã‰ditez .env avec vos clÃ©s API
```

Variables essentielles :
- `ANTHROPIC_API_KEY` - ClÃ© API Claude
- `OPENAI_API_KEY` - ClÃ© API OpenAI (pour embeddings)
- `DATABASE_URL` - Connexion PostgreSQL
- `REDIS_URL` - Connexion Redis

#### Plan de migration vers production

##### 1. CrÃ©er une session DB synchrone pour Celery

```python
# app/models/base.py
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

# Sync engine pour Celery tasks
sync_engine_celery = create_engine(
    settings.database_url_sync,  # postgresql://... (sans +asyncpg)
    pool_size=10,
    max_overflow=20,
    echo=settings.debug,
)

CelerySessionLocal = sessionmaker(
    sync_engine_celery,
    autocommit=False,
    autoflush=False,
)
```

##### 2. Refactoriser les tasks en sync

```python
# app/tasks/tender_tasks.py

@celery_app.task(bind=True, max_retries=3)
def process_tender_document(self, document_id: str):
    """Sync version - production ready."""
    try:
        # Utiliser session sync
        with CelerySessionLocal() as db:
            stmt = select(TenderDocument).where(TenderDocument.id == document_id)
            document = db.execute(stmt).scalar_one_or_none()

            # Storage service (dÃ©jÃ  sync)
            file_content = storage_service.download_file(document.file_path)

            # Parser service (PyPDF2 est sync)
            extraction_result = parser_service.extract_from_pdf_sync(file_content)

            # LLM service - version sync
            if extraction_result["text"].strip():
                # Utiliser httpx ou requests au lieu de AsyncClient
                pass

            document.extracted_text = extraction_result["text"]
            db.commit()

    except Exception as exc:
        raise self.retry(exc=exc, countdown=2 ** self.request.retries)
```

##### 3. Adapter les services

**LLM Service**: CrÃ©er version sync
```python
# app/services/llm_service.py

class LLMService:
    def __init__(self):
        # Version async (pour API FastAPI)
        self.async_client = anthropic.AsyncAnthropic(...)

        # Version sync (pour Celery)
        self.sync_client = anthropic.Anthropic(...)

    async def analyze_tender(self, content: str):
        """Version async pour API."""
        response = await self.async_client.messages.create(...)
        return response

    def analyze_tender_sync(self, content: str):
        """Version sync pour Celery tasks."""
        response = self.sync_client.messages.create(...)
        return response
```

**Parser Service**: DÃ©jÃ  majoritairement sync (PyPDF2)

**Storage Service**: DÃ©jÃ  sync (MinIO SDK)

##### 4. Avantages aprÃ¨s migration

- âœ… ParallÃ©lisme complet (12+ workers)
- âœ… ScalabilitÃ© horizontale
- âœ… Performance production
- âœ… Gestion de charge Ã©levÃ©e (50-100+ documents simultanÃ©s)

##### 5. Estimation

- **Temps**: 2-4 heures de dÃ©veloppement
- **ComplexitÃ©**: Moyenne
- **Risque**: Faible (pattern standard)
- **Tests**: NÃ©cessaires pour validation

#### Pourquoi deux patterns (async API + sync Celery) ?

1. **API FastAPI** reste async:
   - Performance I/O Ã©levÃ©e
   - Gestion efficace de milliers de requÃªtes HTTP concurrentes
   - Standard moderne Python

2. **Celery tasks** deviennent sync:
   - Compatible avec multiprocessing (prefork)
   - Pattern standard et robuste
   - Pas de problÃ¨mes d'event loop

C'est une architecture **hybride courante** dans les applications Python modernes.

## ğŸ“ License

Proprietary - All rights reserved
