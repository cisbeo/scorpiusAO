# ScorpiusAO

**AI Copilot for French Public Tender Bid Management**

Application IA destin√©e aux bid managers pour r√©pondre aux appels d'offres publics fran√ßais, sp√©cialis√©e dans les infrastructures IT, l'h√©bergement datacenter et les services de support IT.

## üöÄ Quick Start

### Infrastructure lanc√©e

Les services d'infrastructure Docker sont actuellement d√©marr√©s et op√©rationnels :

| Service | Status | Port | Interface |
|---------|--------|------|-----------|
| **PostgreSQL** (pgvector) | ‚úÖ Healthy | 5433 | - |
| **Redis** | ‚úÖ Healthy | 6379 | - |
| **RabbitMQ** | ‚úÖ Healthy | 5672 | Management UI: http://localhost:15672 |
| **MinIO** | ‚úÖ Healthy | 9000 | Console: http://localhost:9001 |

### Acc√®s aux interfaces

- **RabbitMQ Management**: http://localhost:15672 (guest/guest)
- **MinIO Console**: http://localhost:9001 (minioadmin/minioadmin)

## üìÅ Structure du projet

```
ScorpiusAO/
‚îú‚îÄ‚îÄ backend/              # API FastAPI + services Python
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/v1/      # Endpoints REST
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/    # LLM, RAG, Parser
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/      # SQLAlchemy models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas/     # Pydantic schemas
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tasks/       # Celery async tasks
‚îÇ   ‚îú‚îÄ‚îÄ alembic/         # Database migrations
‚îÇ   ‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ frontend/            # (√Ä venir) Next.js + TypeScript
‚îî‚îÄ‚îÄ CLAUDE.md           # Documentation pour Claude Code

```

## üõ†Ô∏è Technologies

### Backend
- **API**: FastAPI (Python 3.11+)
- **AI**: Claude Sonnet 4.5, OpenAI Embeddings
- **Database**: PostgreSQL 15 + pgvector
- **Cache**: Redis 7
- **Queue**: RabbitMQ + Celery
- **Storage**: MinIO (S3-compatible)
- **OCR**: Tesseract

### Frontend (√Ä venir)
- **Framework**: Next.js 14+
- **Language**: TypeScript
- **UI**: React + TailwindCSS

## üìã Prochaines √©tapes

### Backend
1. ‚úÖ Structure du projet cr√©√©e
2. ‚úÖ Services d'infrastructure lanc√©s
3. ‚è≥ Cr√©er les migrations de base de donn√©es
4. ‚è≥ Tester les endpoints API
5. ‚è≥ Impl√©menter les services (LLM, RAG, Parser)

### Frontend
1. ‚è≥ Initialiser le projet Next.js
2. ‚è≥ Cr√©er les composants UI
3. ‚è≥ Int√©grer avec l'API backend

## üîß Commandes utiles

### Backend

```bash
cd backend

# Cr√©er et appliquer une migration
alembic revision --autogenerate -m "description"
alembic upgrade head

# D√©marrer l'API (d√©veloppement local)
uvicorn app.main:app --reload --port 8000

# D√©marrer Celery worker (D√âVELOPPEMENT - mode solo pour compatibilit√© asyncio)
celery -A app.core.celery_app worker --pool=solo --loglevel=info

# D√©marrer Celery worker (PRODUCTION - voir note ci-dessous)
# celery -A app.core.celery_app worker --loglevel=info

# Tests
pytest
pytest --cov=app
```

### ‚ö†Ô∏è Note importante sur Celery

**Mode actuel (D√©veloppement)**: `--pool=solo`
- Une seule t√¢che √† la fois
- Compatible avec le code asyncio actuel
- Id√©al pour tests et validation du workflow

**Migration vers Production** (TODO - voir section "Architecture Notes" ci-dessous):
- Refactoriser les tasks Celery en version synchrone
- Utiliser le mode `prefork` pour parall√©lisme
- N√©cessite 2-4h de d√©veloppement

### Docker

```bash
cd backend

# D√©marrer tous les services
docker-compose up -d

# Voir les logs
docker-compose logs -f

# Arr√™ter les services
docker-compose down

# R√©initialiser (supprime les donn√©es)
docker-compose down -v
```

## üìö Documentation

- [CLAUDE.md](CLAUDE.md) - Guide complet pour Claude Code
- [Backend README](backend/README.md) - Documentation backend d√©taill√©e
- API Docs: http://localhost:8000/docs (une fois l'API lanc√©e)

## üéØ Fonctionnalit√©s principales

1. **Analyse d'appels d'offres**
   - Extraction automatique des crit√®res
   - Identification des documents obligatoires
   - Analyse des risques et dates limites

2. **G√©n√©ration de r√©ponses**
   - Sections g√©n√©r√©es par IA adapt√©es au contexte
   - Biblioth√®que de r√©ponses r√©utilisables
   - V√©rification de conformit√© en temps r√©el

3. **Base de connaissances (RAG)**
   - Recherche s√©mantique dans les documents
   - Projets ant√©rieurs et certifications
   - R√©f√©rences clients et √©tudes de cas

4. **Export de documents**
   - G√©n√©ration DUME, DC4
   - Formats sp√©cifiques aux plateformes
   - M√©moire technique complet

## üîê Configuration

Copiez `.env.example` vers `.env` et configurez vos cl√©s API :

```bash
cd backend
cp .env.example .env
# √âditez .env avec vos cl√©s API
```

Variables essentielles :
- `ANTHROPIC_API_KEY` - Cl√© API Claude
- `OPENAI_API_KEY` - Cl√© API OpenAI (pour embeddings)
- `DATABASE_URL` - Connexion PostgreSQL
- `REDIS_URL` - Connexion Redis

## üèóÔ∏è Architecture Notes

### Celery + Asyncio: Migration Production

#### Probl√®me actuel

Les tasks Celery utilisent du code asyncio (AsyncSession, asyncpg) qui n'est pas compatible avec le mode `prefork` multi-processus de Celery.

**Solution temporaire (dev)**: Mode `--pool=solo` (une seule t√¢che √† la fois)

**Solution production**: Refactoriser les tasks en version synchrone

#### Plan de migration vers production

##### 1. Cr√©er une session DB synchrone pour Celery

```python
# app/models/base.py
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

# Sync engine pour Celery tasks
sync_engine_celery = create_engine(
    settings.database_url_sync,  # postgresql://... (sans +asyncpg)
    pool_size=10,
    max_overflow=20,
    echo=settings.debug,
)

CelerySessionLocal = sessionmaker(
    sync_engine_celery,
    autocommit=False,
    autoflush=False,
)
```

##### 2. Refactoriser les tasks en sync

```python
# app/tasks/tender_tasks.py

@celery_app.task(bind=True, max_retries=3)
def process_tender_document(self, document_id: str):
    """Sync version - production ready."""
    try:
        # Utiliser session sync
        with CelerySessionLocal() as db:
            stmt = select(TenderDocument).where(TenderDocument.id == document_id)
            document = db.execute(stmt).scalar_one_or_none()

            # Storage service (d√©j√† sync)
            file_content = storage_service.download_file(document.file_path)

            # Parser service (PyPDF2 est sync)
            extraction_result = parser_service.extract_from_pdf_sync(file_content)

            # LLM service - version sync
            if extraction_result["text"].strip():
                # Utiliser httpx ou requests au lieu de AsyncClient
                pass

            document.extracted_text = extraction_result["text"]
            db.commit()

    except Exception as exc:
        raise self.retry(exc=exc, countdown=2 ** self.request.retries)
```

##### 3. Adapter les services

**LLM Service**: Cr√©er version sync
```python
# app/services/llm_service.py

class LLMService:
    def __init__(self):
        # Version async (pour API FastAPI)
        self.async_client = anthropic.AsyncAnthropic(...)

        # Version sync (pour Celery)
        self.sync_client = anthropic.Anthropic(...)

    async def analyze_tender(self, content: str):
        """Version async pour API."""
        response = await self.async_client.messages.create(...)
        return response

    def analyze_tender_sync(self, content: str):
        """Version sync pour Celery tasks."""
        response = self.sync_client.messages.create(...)
        return response
```

**Parser Service**: D√©j√† majoritairement sync (PyPDF2)

**Storage Service**: D√©j√† sync (MinIO SDK)

##### 4. Avantages apr√®s migration

- ‚úÖ Parall√©lisme complet (12+ workers)
- ‚úÖ Scalabilit√© horizontale
- ‚úÖ Performance production
- ‚úÖ Gestion de charge √©lev√©e (50-100+ documents simultan√©s)

##### 5. Estimation

- **Temps**: 2-4 heures de d√©veloppement
- **Complexit√©**: Moyenne
- **Risque**: Faible (pattern standard)
- **Tests**: N√©cessaires pour validation

#### Pourquoi deux patterns (async API + sync Celery) ?

1. **API FastAPI** reste async:
   - Performance I/O √©lev√©e
   - Gestion efficace de milliers de requ√™tes HTTP concurrentes
   - Standard moderne Python

2. **Celery tasks** deviennent sync:
   - Compatible avec multiprocessing (prefork)
   - Pattern standard et robuste
   - Pas de probl√®mes d'event loop

C'est une architecture **hybride courante** dans les applications Python modernes.

## üìù License

Proprietary - All rights reserved
