# üéØ Roadmap ScorpiusAO

**Derni√®re mise √† jour**: 2 octobre 2025
**Version actuelle**: 0.2.0 (MVP Backend)

---

## üìä √âtat Actuel du Projet

### ‚úÖ Phase 1 - Backend MVP (COMPL√âT√â - Oct 2025)

**Infrastructure & Services**

- ‚úÖ Docker Compose orchestration (PostgreSQL, Redis, RabbitMQ, MinIO)
- ‚úÖ Base de donn√©es compl√®te (9 tables + pgvector)
- ‚úÖ API REST FastAPI (8 endpoints)
- ‚úÖ Storage service (MinIO S3)
- ‚úÖ LLM service (Claude Sonnet 4.5 + cache Redis)
- ‚úÖ Parser service (PyPDF2, pdfplumber, OCR Tesseract)
- ‚úÖ Pipeline async Celery robuste

**Fonctionnalit√©s Cl√©s Impl√©ment√©es**

- ‚úÖ Extraction structure hi√©rarchique (sections, TOC, num√©rotation)
- ‚úÖ D√©tection automatique sections cl√©s (18/18 processus ITIL, crit√®res, exclusions)
- ‚úÖ Optimisation hi√©rarchique LLM (-20% tokens)
- ‚úÖ Analyse IA compl√®te (r√©sum√©, exigences, risques, d√©lais)
- ‚úÖ Extraction crit√®res structur√©s avec poids

**Tests & Documentation**

- ‚úÖ Suite tests E2E compl√®te
- ‚úÖ Proc√©dure validation document√©e
- ‚úÖ R√©sultats valid√©s sur tender VSGP-AO r√©el (377 sections, $0.12/analyse)

**M√©triques de Performances Valid√©es**

- Extraction: 45s pour 3 documents (objectif: <2 min) ‚úÖ
- Analyse LLM: 8s (objectif: <15s) ‚úÖ
- Co√ªt: $0.12/tender (objectif: <$0.20) ‚úÖ
- D√©tection ITIL: 100% recall (objectif: >90%) ‚úÖ

---

## üöÄ Prochaines √âtapes

### üìÖ Priorit√© Imm√©diate (2-3 semaines) - Solution 5.5 Adaptive Analysis

#### 1. Analyse LLM Am√©lior√©e - Solution 5.5 (Adaptive)

**Priorit√©**: CRITIQUE | **Effort**: 12 semaines (6 sprints) | **Status**: üìã Planifi√©
**Issues**: [#3](https://github.com/cisbeo/scorpiusAO/issues/3), [#4](https://github.com/cisbeo/scorpiusAO/issues/4)

**Architecture recommand√©e**: Analyse adaptative selon complexit√© de l'AO

**Phase 1 - Sprint 1-2 (MVP - Solution 5 Hybrid)**: 2 semaines

- [ ] Executive analysis (2 passes: classification + synth√®se th√©matique)
- ‚úÖ Int√©gration RAG (embeddings + Q&A endpoint) - **COMPL√âT√â 3 oct 2025**
  - ‚úÖ Endpoint `/tenders/{id}/ask` op√©rationnel
  - ‚úÖ Cache Redis 1h TTL
  - ‚úÖ Recall@5: 100%, Co√ªt: $0.016/tender
  - ‚úÖ Tests E2E valid√©s
- [ ] Dashboard React avec risk scoring, KPI, timeline
- [ ] Composant chat Q&A avec r√©f√©rences sources
- **Co√ªt**: $0.55/AO + $0.01/question
- **Temps**: 45 secondes
- **Pr√©cision**: 85-90%

**Phase 2 - Sprint 3-4 (Premium - Solution 6 Multi-Passes)**: 2 semaines

- [ ] Pass 1: Analyse d√©taill√©e de TOUTES les sections (377 sections)
- [ ] Pass 2: Synth√®se th√©matique enrichie
- [ ] Pass 3: Cross-analysis (contradictions, d√©pendances, FAQ pr√©-calcul√©e)
- [ ] Feature flag "Deep Analysis" (opt-in)
- [ ] A/B testing (50% users avec Sol 5, 50% avec Sol 6)
- **Co√ªt**: $3.76/AO + $0.01/question
- **Temps**: 3-4 minutes
- **Pr√©cision**: 95-98%

**Phase 3 - Sprint 5-6 (Adaptive - Solution 5.5)**: 2 semaines

- [ ] Impl√©mentation scoring automatique de complexit√© (0-100)
- [ ] S√©lection automatique du mode d'analyse:
  - Complexit√© < 50: Fast mode (Solution 5) ‚Üí $0.55
  - Complexit√© 50-75: Selective mode (50 sections cl√©s) ‚Üí $1.50
  - Complexit√© > 75: Deep mode (Solution 6) ‚Üí $3.76
- [ ] Machine learning: affiner scoring selon feedback utilisateurs
- [ ] Mode adaptatif par d√©faut pour tous
- **Co√ªt moyen**: $1.67/AO (pond√©r√©)
- **ROI**: +‚Ç¨47 gain marginal vs Solution 5, +81% gain vs manuel

**Crit√®res de complexit√© d√©tect√©s**:

- Nombre de sections (max 30 points)
- Pr√©sence de tableaux (max 20 points)
- Mots-cl√©s complexit√© (max 20 points): p√©nalit√©s, coefficient multiplicateur, exclusion, r√©versibilit√©
- Montant estim√© (max 15 points)
- Dur√©e contrat (max 15 points)

**Valeur ajout√©e**:

- ‚úÖ D√©tection automatique contradictions entre sections
- ‚úÖ Graphe de d√©pendances entre sections
- ‚úÖ FAQ pr√©-calcul√©e (20-30 questions)
- ‚úÖ Confidence scoring par section
- ‚úÖ 5 niveaux de navigation front (executive ‚Üí th√®me ‚Üí section ‚Üí Q&A ‚Üí advanced)
- ‚úÖ R√©utilisation analyses pour futurs AO similaires

---

#### 2. Am√©lioration Parsing Tableaux

**Priorit√©**: HAUTE | **Effort**: 1-2 semaines | **Status**: üìã Document√©

**3 Solutions Compl√©mentaires**:

- **Phase 1**: Enrichissement Prompt (2-4h) ‚Üí +20% qualit√©
- **Phase 2**: Post-Processing (8-16h) ‚Üí +50% qualit√© totale
- **Phase 3**: Int√©gration Camelot (4-8h) ‚Üí 90-98% qualit√© finale

---

#### 3. Compl√©ter RAG Service (Int√©gr√© dans Solution 5.5)

**Priorit√©**: CRITIQUE | **Effort**: 2-3 jours | **Status**: üöß EN COURS (partiellement compl√©t√© - 3 oct 2025)

**T√¢ches compl√©t√©es**:

- ‚úÖ Impl√©menter embeddings OpenAI r√©els (text-embedding-3-small)
- ‚úÖ Tester recherche vectorielle pgvector (cosine similarity)
- ‚úÖ Valider chunking strategy (recall@5 = 100%, objectif: >80%)
- ‚úÖ API endpoint `/tenders/{id}/ask` avec RAG
- ‚úÖ Cache questions fr√©quentes (Redis 1h TTL)
- ‚úÖ M√©thodes synchrones pour Celery (5 m√©thodes)
- ‚úÖ Tests E2E complets avec donn√©es de test (recall@5=100%, co√ªt=$0.016/tender)
- ‚úÖ Sources enrichies avec `document_filename` et m√©tadonn√©es compl√®tes

**T√¢ches en attente**:

- [ ] **Pipeline Celery STEP 2 : Ingestion RAG automatique apr√®s extraction**
  - Attention : l'ingestion automatique doit bien taggu√© les tenders ing√©r√©s comme des tenders en cours et pas des tenders historical_tenders
  - Code existant: `rag_service.ingest_document_sync()` ‚úÖ
  - Int√©gration dans `process_tender_document()` ‚ùå NON FAIT
  - Les 377 sections du VSGP-AO sont extraites mais **pas embed√©es**
  - Seules les donn√©es de test (2 sections) ont des embeddings
- [ ] Pipeline STEP 5: Find similar tenders (recherche dans historical_tenders)
- [ ] Ingestion manuelle des documents existants (CCTP.pdf, CCAP.pdf, RC.pdf)

**R√©sultats valid√©s** (sur donn√©es de test uniquement):

- Recall@5: 100% (objectif: >80%) ‚úÖ
- Answer Quality: 80% (objectif: >80%) ‚úÖ
- Co√ªt: $0.016/tender (objectif: <$0.02) ‚úÖ
- Temps r√©ponse Q&A: <100ms (cache hit), 3-4s (cache miss)

**Limitations actuelles**:

- ‚ö†Ô∏è Les embeddings ne sont cr√©√©s QUE dans les tests E2E (donn√©es fictives)
- ‚ö†Ô∏è Les vrais documents (377 sections VSGP-AO) n'ont PAS d'embeddings
- ‚ö†Ô∏è L'API `/tenders/{id}/ask` utilise les donn√©es de test (pages incorrectes)
- ‚ö†Ô∏è Les pages retourn√©es ne correspondent pas aux vrais documents (ex: page 2 au lieu de page 34)

**Prochaines √©tapes** (Sprint 2):

- [ ] FAQ pr√©-calcul√©e (20-30 questions auto-g√©n√©r√©es)
- [x] **Int√©gration Knowledge Base (`past_proposals`, `historical_tenders`)** ‚úÖ (3 oct 2025)
  - ‚úÖ Mod√®les SQLAlchemy cr√©√©s
  - ‚úÖ Migration Alembic appliqu√©e
  - ‚úÖ Archive Service + endpoint API
  - ‚úÖ RAG batch ingestion
  - ‚úÖ LLM Service enrichi avec KB
  - Voir: [Issue #2 - R√âSOLU](https://github.com/cisbeo/scorpiusAO/issues/2)
- [ ] Int√©gration `case_studies` et `certifications` (optionnel)
- [ ] Composant frontend Chat Q&A
- [ ] Re-ranking avec Cohere/Voyage (optionnel)

---

#### 3bis. Compl√©ter Pipeline Celery - Ingestion RAG Automatique

**Priorit√©**: HAUTE | **Effort**: 1-2 jours | **Status**: ‚è≥ √Ä FAIRE

**Objectif**: Cr√©er automatiquement les embeddings apr√®s l'extraction des sections pour que l'API retourne les **vraies pages** des documents.

**Probl√®me actuel**:

- `process_tender_document()` extrait les sections mais ne cr√©e pas les embeddings
- R√©sultat : 377 sections extraites, 0 embeddings en production
- L'API utilise les embeddings de test (2 sections fictives avec pages incorrectes)

**T√¢ches**:

- [ ] **Ajouter STEP 2 dans `process_tender_document()`** (apr√®s ligne 183)
  - Appeler `rag_service.ingest_document_sections_sync(db, document_id, tender_id)`
  - Cr√©er embeddings pour toutes les sections non-TOC avec contenu
  - Logger le nombre d'embeddings cr√©√©s (ex: 202 sections ‚Üí ~140 embeddings)
  - Gestion d'erreur : si √©chec, logger mais ne pas bloquer le pipeline
- [ ] **Cr√©er script CLI pour ingestion manuelle des documents existants**
  - `python scripts/ingest_tender_documents.py --tender_id=<uuid>`
  - Ing√©rer les 377 sections du tender VSGP-AO test (3cfc8207-f275-4e53-ae0c-bead08cc45b7)
  - Option `--force` pour r√©ing√©rer (supprimer anciens embeddings)
- [ ] **Valider avec le vrai CCTP.pdf**
  - 202 sections ‚Üí ~140 embeddings attendus
  - V√©rifier que les pages retourn√©es sont correctes (ex: section 4.1.5 = page 34)
- [ ] **Mettre √† jour tests E2E** pour valider l'ingestion automatique
  - Test que `process_tender_document()` cr√©e bien les embeddings
  - V√©rifier le nombre d'embeddings cr√©√©s

**B√©n√©fice attendu**:

- ‚úÖ Les pages retourn√©es par l'API seront les **vraies pages** du CCTP.pdf
- ‚úÖ Plus besoin de donn√©es de test : production avec vrais documents
- ‚úÖ Pipeline complet : Upload ‚Üí Extract ‚Üí Embed ‚Üí Q&A op√©rationnel

**Co√ªt estim√©**: 377 sections √ó $0.0001/embed = ~$0.04 par tender

---

#### 4. WebSocket Notifications

**Priorit√©**: MOYENNE | **Effort**: 2 jours | **Status**: ‚è≥ Non d√©marr√©

Progress updates temps r√©el via WebSocket + Redis Pub/Sub

---

#### 5. Tests Unitaires Complets

**Priorit√©**: HAUTE | **Effort**: 3-4 jours | **Status**: ‚è≥ √Ä compl√©ter

Coverage > 80% + CI/CD GitHub Actions

---

### üìÖ Moyen Terme (1 mois)

#### 5. Frontend MVP (Next.js 14)

**Priorit√©**: HAUTE | **Effort**: 2 semaines

- Dashboard tenders
- Upload documents (drag & drop)
- Visualisation analyses
- √âditeur basique r√©ponses

#### 6. Int√©grations Externes

**Priorit√©**: MOYENNE | **Effort**: 1 semaine

- Scraper BOAMP automatique
- Connecteur AWS PLACE
- Notifications email

#### 7. S√©curit√© Production

**Priorit√©**: HAUTE | **Effort**: 3-4 jours

- Authentification JWT + refresh tokens
- RBAC (3 r√¥les: admin, bid_manager, viewer)
- Rate limiting Redis
- Validation s√©curis√©e uploads

---

### üìÖ Long Terme (3 mois)

#### 8. Fonctionnalit√©s Avanc√©es

- **G√©n√©ration M√©mo Technique**: Templates Jinja2, export Word/PDF
- **Export DUME/DC4**: Format XML europ√©en standard
- **Scoring Simulation**: Pr√©diction scores avec IA
- **√âditeur Collaboratif**: Temps r√©el avec WebSocket

#### 9. Optimisations Production

- **Cache Multi-Niveaux**: CDN + Redis L1/L2
- **Monitoring**: Grafana + Sentry + ELK Stack
- **Scaling Kubernetes**: HPA 2-10 replicas, 99.9% uptime

---

## üìä Planning

| Phase | Dur√©e | Priorit√© | Status |
|-------|-------|----------|--------|
| Phase 1 - MVP Backend | ‚úÖ 3 semaines | HAUTE | ‚úÖ DONE |
| **Solution 5.5 Adaptive (Sprint 1-6)** | **12 semaines** | **CRITIQUE** | üìã Planifi√© |
| ‚îú‚îÄ Sprint 1-2: Solution 5 (MVP) | 2 semaines | CRITIQUE | ‚è≥ √Ä d√©marrer |
| ‚îú‚îÄ Sprint 3-4: Solution 6 (Premium) | 2 semaines | CRITIQUE | ‚è≥ Planifi√© |
| ‚îî‚îÄ Sprint 5-6: Adaptive (ML) | 2 semaines | CRITIQUE | ‚è≥ Planifi√© |
| Court terme (Parsing + Tests) | 2 semaines | HAUTE | üöß EN COURS |
| Moyen terme | 1 mois | HAUTE | ‚è≥ Planifi√© |
| Long terme | 3 mois | MOYENNE | ‚è≥ Planifi√© |

**Total estim√© avec Solution 5.5**: ~7 mois ETP

---

## üéØ Crit√®res de Succ√®s

### Solution 5.5 Adaptive (Priorit√© Critique)

- [ ] **Sprint 1-2**: Solution 5 fonctionnelle
  - Executive analysis en <45 sec
  - RAG Q&A en <2 sec
  - Dashboard React avec risk scoring
  - Chat avec r√©f√©rences sources
- [ ] **Sprint 3-4**: Solution 6 fonctionnelle
  - Analyse 377 sections en 3-4 min
  - D√©tection contradictions automatique
  - FAQ pr√©-calcul√©e (20-30 questions)
  - A/B testing valid√©
- [ ] **Sprint 5-6**: Solution 5.5 en production
  - Scoring complexit√© pr√©cision >85%
  - Co√ªt moyen <$2/AO
  - ROI >‚Ç¨600/AO
  - Satisfaction utilisateur >90%

### Court Terme

- [ ] Parsing tableaux: qualit√© > 85%
- [ ] RAG Service: recall@5 > 80%
- [ ] Tests: coverage > 80%
- [ ] WebSocket: latence < 100ms

### Moyen Terme

- [ ] Frontend: TTI < 3s (Lighthouse > 90)
- [ ] S√©curit√©: 0 vuln√©rabilit√©s critiques
- [ ] BOAMP: Import 10+ tenders/jour
- [ ] API: P95 latence < 300ms

### Long Terme

- [ ] Scoring: pr√©cision > 70%
- [ ] Production: 99.9% uptime
- [ ] Performance: Analyse < 60s P95
- [ ] Scalabilit√©: 100+ users concurrents

---

## üöÄ Quick Wins Imm√©diats

### Priorit√© Absolue (Sprint 1-2)

1. **Solution 5 MVP** (2 semaines) ‚Üí Analyse adaptative op√©rationnelle
   - Executive analysis avec 2 passes
   - RAG Service complet (embeddings + Q&A)
   - Dashboard React basique
   - ROI: +‚Ç¨599/AO vs manuel

### Court Terme

2. **Parsing Tableaux Phase 1** (4h) ‚Üí +20% qualit√©
3. **Tests Unitaires** (2j) ‚Üí Confiance d√©ploiement
4. **WebSocket** (2j) ‚Üí Meilleure UX

**Total Sprint 1-2**: 2 semaines ‚Üí Solution 5 MVP utilisable en production

---

## üìö Ressources

### Humaines

- 1 Dev Backend Python
- 1 Dev Frontend React/Next.js
- 0.5 DevOps
- 0.5 QA

### Budget Mensuel (Production)

- Infrastructure: $200-500
- **Claude API**: $300-800 (avec Solution 5.5 adaptive)
  - 50 AO/mois √ó $1.67 moyen = ~$83.50
  - 500 questions RAG/mois √ó $0.01 = ~$5
  - Marge s√©curit√© + autres usages
- **OpenAI Embeddings**: $50-100
- SaaS: $100-150
- **Total**: ~$650-1,550/mois

**ROI estim√©** (50 AO/mois):

- Co√ªt outil: ~$650/mois
- Gain temps bid managers: 50 AO √ó ‚Ç¨599 = **‚Ç¨29,950/mois**
- **ROI net**: **‚Ç¨29,300/mois** (45√ó le co√ªt)

---

**Prochaine r√©vision**: 15 octobre 2025
