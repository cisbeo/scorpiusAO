# ðŸ§ª Tests RAG Service - PHASE 1: Embedding Engine

## ðŸ“‹ Vue d'ensemble

Script de test automatisÃ© pour valider les dÃ©veloppements de la PHASE 1 (Embedding Engine) du RAG Service.

**3 Use Cases testÃ©s** :
1. **Embedding + Cache Redis** : Validation cache (miss â†’ hit)
2. **Batch Embeddings** : Optimisation coÃ»ts API (1 appel pour N textes)
3. **Workflow Complet** : Ingestion + Recherche sÃ©mantique

---

## ðŸ”§ PrÃ©requis

### 1. Configuration environnement

CrÃ©er/Ã©diter `.env` :
```bash
# OpenAI API (OBLIGATOIRE)
OPENAI_API_KEY=sk-proj-...

# Redis (OBLIGATOIRE pour Use Case 1 et 2)
REDIS_URL=redis://localhost:6379/0

# PostgreSQL (OBLIGATOIRE pour Use Case 3)
DATABASE_URL=postgresql+asyncpg://scorpius:scorpius_password@localhost:5433/scorpius_db
```

### 2. Infrastructure dÃ©marrÃ©e

```bash
# DÃ©marrer Redis (Use Case 1 & 2)
docker-compose up -d redis

# DÃ©marrer PostgreSQL avec pgvector (Use Case 3)
docker-compose up -d postgres

# VÃ©rifier que les services sont up
docker-compose ps
```

### 3. Base de donnÃ©es migrÃ©e (Use Case 3)

```bash
cd backend
alembic upgrade head
```

### 4. DÃ©pendances Python installÃ©es

```bash
cd backend
pip install -r requirements.txt
```

---

## ðŸš€ Utilisation

### ExÃ©cuter tous les tests

```bash
python backend/tests/run_rag_tests.py --all
```

### ExÃ©cuter un test spÃ©cifique

```bash
# Use Case 1 uniquement
python backend/tests/run_rag_tests.py --use-case 1

# Use Case 2 uniquement
python backend/tests/run_rag_tests.py --use-case 2

# Use Case 3 uniquement
python backend/tests/run_rag_tests.py --use-case 3
```

### Aide

```bash
python backend/tests/run_rag_tests.py --help
```

---

## ðŸ“Š Use Cases dÃ©taillÃ©s

### âœ… Use Case 1: Embedding + Cache Redis

**Objectif** : Valider crÃ©ation embedding + cache Redis

**Ce qui est testÃ©** :
- âœ“ Appel OpenAI Embeddings API
- âœ“ CrÃ©ation embedding (1536 dimensions)
- âœ“ Stockage dans Redis avec TTL 30 jours
- âœ“ Cache hit sur 2Ã¨me appel (pas de nouvel appel API)
- âœ“ Gain de performance du cache

**Sortie attendue** :
```
USE CASE 1: EMBEDDING + CACHE REDIS
================================================================================

â–º Test 1.1: Premier appel (cache miss)
âœ… Embedding crÃ©Ã©: 1536 dimensions
   Preview: [0.1234, -0.5678, 0.9012, ...]
   Temps: 245ms (avec appel OpenAI)

â–º Test 1.2: DeuxiÃ¨me appel (cache hit)
âœ… Embedding rÃ©cupÃ©rÃ© du cache
   Temps: 3ms (depuis Redis)
   Gain de performance: 98%

âœ… Les embeddings sont identiques (cache fonctionne)

USE CASE 1: âœ… PASSED
  â€¢ Embedding Dimensions: 1536
  â€¢ Cache Hit Speedup: 98%
  â€¢ Api Call Time Ms: 245
  â€¢ Cache Time Ms: 3
```

**PrÃ©requis** : Redis running

---

### âœ… Use Case 2: Batch Embeddings

**Objectif** : Valider batch embeddings (optimisation coÃ»ts)

**Ce qui est testÃ©** :
- âœ“ Batch de 5 textes â†’ 1 seul appel API
- âœ“ Tous les embeddings crÃ©Ã©s (1536 dimensions chacun)
- âœ“ Ordre prÃ©servÃ© (embeddings correspondent aux textes)
- âœ“ Ã‰conomie de 4 appels API vs. appels individuels

**Sortie attendue** :
```
USE CASE 2: BATCH EMBEDDINGS (OPTIMISATION COÃ›TS)
================================================================================

â–º Test 2.1: Batch de 5 textes
â„¹ï¸  Sans batch: 5 appels API
â„¹ï¸  Avec batch: 1 appel API â†’ Ã©conomie de 4 appels

âœ… 5 embeddings crÃ©Ã©s en 1 appel API
   Temps total: 198ms
   Temps moyen par embedding: 39ms
   [0] 1536 dim - Infrastructure: 147 switchs Cisco...
   [1] 1536 dim - Virtualisation: 54 VMs VMware ESXi...
   [2] 1536 dim - Stockage: SAN Fibre Channel 100 TB...
   [3] 1536 dim - RÃ©seau: Firewall Palo Alto PA-5220...
   [4] 1536 dim - Monitoring: Supervision Zabbix 24/7...

âœ… Batch embeddings validÃ©

USE CASE 2: âœ… PASSED
  â€¢ Texts Count: 5
  â€¢ Api Calls: 1
  â€¢ Savings: 4 appels
  â€¢ Time Ms: 198
  â€¢ Estimated Savings Pct: 80%
```

**PrÃ©requis** : Redis running

---

### âœ… Use Case 3: Workflow Complet

**Objectif** : Valider ingestion + recherche sÃ©mantique

**Ce qui est testÃ©** :
- âœ“ Chunking du document (texte â†’ chunks)
- âœ“ CrÃ©ation embeddings pour chaque chunk
- âœ“ Stockage dans pgvector (PostgreSQL)
- âœ“ Recherche sÃ©mantique (cosine similarity)
- âœ“ Tri par score de similaritÃ©
- âœ“ Scores cohÃ©rents (>0.6 pour matches pertinents)

**Sortie attendue** :
```
USE CASE 3: WORKFLOW COMPLET (INGESTION + RECHERCHE)
================================================================================

â–º Test 3.1: Ingestion du document dans pgvector
â„¹ï¸  Document ID: a1b2c3d4-...
â„¹ï¸  Type: past_proposal
â„¹ï¸  Taille: 456 caractÃ¨res

âœ… 5 chunks crÃ©Ã©s et stockÃ©s avec embeddings
   Temps d'ingestion: 234ms

â–º Test 3.2: Recherches sÃ©mantiques
â„¹ï¸  ðŸ” Recherche: 'Quelles certifications possÃ©dez-vous ?'
   [1] Score: 0.847 - Notre sociÃ©tÃ© possÃ¨de la certification ISO 27001 pour la sÃ©curitÃ©...
   [2] Score: 0.723 - Nos datacenters sont certifiÃ©s Tier 3 avec redondance N+1...
   Temps de recherche: 87ms

â„¹ï¸  ðŸ” Recherche: 'Quelle est votre infrastructure rÃ©seau ?'
   [1] Score: 0.891 - Nous gÃ©rons une infrastructure de 147 switchs Cisco et 54 VMs...
   [2] Score: 0.654 - Notre Ã©quipe technique comprend 12 ingÃ©nieurs certifiÃ©s...
   Temps de recherche: 65ms

â„¹ï¸  ðŸ” Recherche: 'Quel est votre niveau de supervision ?'
   [1] Score: 0.879 - Nous assurons une supervision 24/7 avec Zabbix et un SLA 99.9%...
   [2] Score: 0.701 - Nos datacenters sont certifiÃ©s Tier 3 avec redondance N+1...
   Temps de recherche: 72ms

âœ… Workflow complet validÃ©

USE CASE 3: âœ… PASSED
  â€¢ Chunks Created: 5
  â€¢ Ingestion Time Ms: 234
  â€¢ Queries Tested: 3
  â€¢ Avg Similarity Score: 0.839
  â€¢ Results Found: 6
```

**PrÃ©requis** : Redis + PostgreSQL running, migrations appliquÃ©es

---

## ðŸ› DÃ©pannage

### Erreur: "OPENAI_API_KEY non configurÃ©"

```bash
# VÃ©rifier .env
cat .env | grep OPENAI_API_KEY

# Ajouter la clÃ© si manquante
echo "OPENAI_API_KEY=sk-proj-..." >> .env
```

### Erreur: "Redis connection refused"

```bash
# DÃ©marrer Redis
docker-compose up -d redis

# VÃ©rifier que Redis est accessible
redis-cli ping  # Doit rÃ©pondre "PONG"
```

### Erreur: "Database connection failed" (Use Case 3)

```bash
# DÃ©marrer PostgreSQL
docker-compose up -d postgres

# Appliquer migrations
cd backend
alembic upgrade head

# VÃ©rifier connexion
psql -h localhost -p 5433 -U scorpius -d scorpius_db -c "SELECT 1"
```

### Erreur: "pgvector extension not installed"

```bash
# Se connecter Ã  PostgreSQL
psql -h localhost -p 5433 -U scorpius -d scorpius_db

# Installer pgvector
CREATE EXTENSION IF NOT EXISTS vector;
\q
```

### Erreur: "Rate limit exceeded"

Si vous atteignez la limite de rate OpenAI :
- Attendez quelques secondes
- Les tests ont un retry automatique (3 tentatives)
- VÃ©rifiez vos quotas OpenAI

---

## ðŸ“ˆ MÃ©triques de succÃ¨s

### Use Case 1 - Cache
- âœ… Cache hit speedup: >90%
- âœ… Embedding dimensions: 1536
- âœ… Cache time: <10ms

### Use Case 2 - Batch
- âœ… API calls: 1 (au lieu de N)
- âœ… Savings: N-1 appels
- âœ… Time per embedding: <50ms

### Use Case 3 - Workflow
- âœ… Chunks created: >0
- âœ… Avg similarity score: >0.7
- âœ… Search time: <200ms

---

## ðŸ”„ IntÃ©gration Continue

Pour intÃ©grer ces tests dans CI/CD :

```yaml
# .github/workflows/test-rag.yml
name: RAG Service Tests

on: [push, pull_request]

jobs:
  test-rag:
    runs-on: ubuntu-latest

    services:
      redis:
        image: redis:7
        ports:
          - 6379:6379

      postgres:
        image: pgvector/pgvector:pg15
        env:
          POSTGRES_PASSWORD: scorpius_password
          POSTGRES_DB: scorpius_db
        ports:
          - 5433:5432

    steps:
      - uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          cd backend
          pip install -r requirements.txt

      - name: Run migrations
        run: |
          cd backend
          alembic upgrade head

      - name: Run RAG tests
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          python backend/tests/run_rag_tests.py --all
```

---

## ðŸ“ Notes

- **CoÃ»ts OpenAI** : Les tests coÃ»tent ~$0.001 par exÃ©cution complÃ¨te (embeddings text-embedding-3-small)
- **Cache** : Le cache Redis persiste entre les exÃ©cutions (TTL 30 jours)
- **DonnÃ©es de test** : Les donnÃ©es insÃ©rÃ©es dans PostgreSQL ne sont pas nettoyÃ©es automatiquement
- **Logs** : Pour plus de logs, dÃ©finir `LOG_LEVEL=DEBUG` dans `.env`

---

## ðŸŽ¯ Prochaines Ã©tapes

AprÃ¨s validation de la PHASE 1 :
- PHASE 2 : Smart Chunking (chunking adaptatif par type de document)
- PHASE 3 : IntÃ©gration Pipeline Celery
- PHASE 4 : API Endpoints REST
- PHASE 5 : Reranking

Voir [RAG_SERVICE_IMPLEMENTATION_PLAN.md](../../RAG_SERVICE_IMPLEMENTATION_PLAN.md) pour le plan complet.
